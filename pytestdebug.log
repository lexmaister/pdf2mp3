versions pytest-8.4.0, python-3.12.3.final.0
invocation_dir=/app
cwd=/app
args=('tests/test_cli.py', '-v', '--debug')

  pytest_cmdline_main [hook]
      config: <_pytest.config.Config object at 0x7ff839ea2b70>
    pytest_plugin_registered [hook]
        plugin: <Session  exitstatus='<UNSET>' testsfailed=0 testscollected=0>
        plugin_name: session
        manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
    finish pytest_plugin_registered --> [] [hook]
    pytest_configure [hook]
        config: <_pytest.config.Config object at 0x7ff839ea2b70>
      pytest_plugin_registered [hook]
          plugin: <_pytest.cacheprovider.LFPlugin object at 0x7ff839798860>
          plugin_name: lfplugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.cacheprovider.NFPlugin object at 0x7ff839900f20>
          plugin_name: nfplugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
    early skip of rewriting module: faulthandler [assertion]
      pytest_plugin_registered [hook]
          plugin: <class '_pytest.legacypath.LegacyTmpdirPlugin'>
          plugin_name: legacypath-tmpdir
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
    early skip of rewriting module: pdb [assertion]
    early skip of rewriting module: cmd [assertion]
    early skip of rewriting module: code [assertion]
    early skip of rewriting module: codeop [assertion]
      pytest_plugin_registered [hook]
          plugin: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
          plugin_name: 140704093650528
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.config.Config object at 0x7ff839ea2b70>
          plugin_name: pytestconfig
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.mark' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/mark/__init__.py'>
          plugin_name: mark
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.main' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/main.py'>
          plugin_name: main
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.runner' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/runner.py'>
          plugin_name: runner
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.fixtures' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/fixtures.py'>
          plugin_name: fixtures
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.helpconfig' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/helpconfig.py'>
          plugin_name: helpconfig
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.python' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/python.py'>
          plugin_name: python
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.terminal' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/terminal.py'>
          plugin_name: terminal
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.debugging' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/debugging.py'>
          plugin_name: debugging
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.unittest' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/unittest.py'>
          plugin_name: unittest
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.capture' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/capture.py'>
          plugin_name: capture
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.skipping' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/skipping.py'>
          plugin_name: skipping
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.legacypath' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/legacypath.py'>
          plugin_name: legacypath
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.tmpdir' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/tmpdir.py'>
          plugin_name: tmpdir
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.monkeypatch' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/monkeypatch.py'>
          plugin_name: monkeypatch
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.recwarn' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/recwarn.py'>
          plugin_name: recwarn
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.pastebin' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/pastebin.py'>
          plugin_name: pastebin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.assertion' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/assertion/__init__.py'>
          plugin_name: assertion
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.junitxml' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/junitxml.py'>
          plugin_name: junitxml
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.doctest' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/doctest.py'>
          plugin_name: doctest
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.cacheprovider' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/cacheprovider.py'>
          plugin_name: cacheprovider
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.freeze_support' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/freeze_support.py'>
          plugin_name: freeze_support
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.setuponly' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/setuponly.py'>
          plugin_name: setuponly
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.setupplan' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/setupplan.py'>
          plugin_name: setupplan
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.stepwise' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/stepwise.py'>
          plugin_name: stepwise
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.unraisableexception' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/unraisableexception.py'>
          plugin_name: unraisableexception
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.threadexception' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/threadexception.py'>
          plugin_name: threadexception
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.warnings' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/warnings.py'>
          plugin_name: warnings
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.logging' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/logging.py'>
          plugin_name: logging
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.reports' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/reports.py'>
          plugin_name: reports
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.faulthandler' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/faulthandler.py'>
          plugin_name: faulthandler
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <CaptureManager _method='fd' _global_capturing=<MultiCapture out=<FDCapture 1 oldfd=5 _state='suspended' tmpfile=<_io.TextIOWrapper name="<_io.FileIO name=6 mode='rb+' closefd=True>" mode='r+' encoding='utf-8'>> err=<FDCapture 2 oldfd=7 _state='suspended' tmpfile=<_io.TextIOWrapper name="<_io.FileIO name=8 mode='rb+' closefd=True>" mode='r+' encoding='utf-8'>> in_=<FDCapture 0 oldfd=3 _state='started' tmpfile=<_io.TextIOWrapper name='/dev/null' mode='r' encoding='utf-8'>> _state='suspended' _in_suspended=False> _capture_fixture=None>
          plugin_name: capturemanager
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
          plugin_name: session
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.cacheprovider.LFPlugin object at 0x7ff839798860>
          plugin_name: lfplugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.cacheprovider.NFPlugin object at 0x7ff839900f20>
          plugin_name: nfplugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <class '_pytest.legacypath.LegacyTmpdirPlugin'>
          plugin_name: legacypath-tmpdir
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.terminal.TerminalReporter object at 0x7ff8397ad010>
          plugin_name: terminalreporter
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.logging.LoggingPlugin object at 0x7ff83976e6c0>
          plugin_name: logging-plugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
    finish pytest_configure --> [] [hook]
    pytest_sessionstart [hook]
        session: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
      pytest_plugin_registered [hook]
          plugin: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
          plugin_name: 140704093650528
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.config.Config object at 0x7ff839ea2b70>
          plugin_name: pytestconfig
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.mark' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/mark/__init__.py'>
          plugin_name: mark
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.main' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/main.py'>
          plugin_name: main
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.runner' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/runner.py'>
          plugin_name: runner
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.fixtures' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/fixtures.py'>
          plugin_name: fixtures
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.helpconfig' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/helpconfig.py'>
          plugin_name: helpconfig
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.python' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/python.py'>
          plugin_name: python
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.terminal' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/terminal.py'>
          plugin_name: terminal
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.debugging' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/debugging.py'>
          plugin_name: debugging
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.unittest' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/unittest.py'>
          plugin_name: unittest
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.capture' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/capture.py'>
          plugin_name: capture
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.skipping' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/skipping.py'>
          plugin_name: skipping
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.legacypath' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/legacypath.py'>
          plugin_name: legacypath
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.tmpdir' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/tmpdir.py'>
          plugin_name: tmpdir
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.monkeypatch' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/monkeypatch.py'>
          plugin_name: monkeypatch
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.recwarn' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/recwarn.py'>
          plugin_name: recwarn
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.pastebin' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/pastebin.py'>
          plugin_name: pastebin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.assertion' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/assertion/__init__.py'>
          plugin_name: assertion
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.junitxml' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/junitxml.py'>
          plugin_name: junitxml
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.doctest' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/doctest.py'>
          plugin_name: doctest
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.cacheprovider' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/cacheprovider.py'>
          plugin_name: cacheprovider
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.freeze_support' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/freeze_support.py'>
          plugin_name: freeze_support
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.setuponly' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/setuponly.py'>
          plugin_name: setuponly
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.setupplan' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/setupplan.py'>
          plugin_name: setupplan
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.stepwise' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/stepwise.py'>
          plugin_name: stepwise
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.unraisableexception' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/unraisableexception.py'>
          plugin_name: unraisableexception
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.threadexception' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/threadexception.py'>
          plugin_name: threadexception
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.warnings' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/warnings.py'>
          plugin_name: warnings
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.logging' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/logging.py'>
          plugin_name: logging
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.reports' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/reports.py'>
          plugin_name: reports
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <module '_pytest.faulthandler' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/faulthandler.py'>
          plugin_name: faulthandler
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <CaptureManager _method='fd' _global_capturing=<MultiCapture out=<FDCapture 1 oldfd=5 _state='suspended' tmpfile=<_io.TextIOWrapper name="<_io.FileIO name=6 mode='rb+' closefd=True>" mode='r+' encoding='utf-8'>> err=<FDCapture 2 oldfd=7 _state='suspended' tmpfile=<_io.TextIOWrapper name="<_io.FileIO name=8 mode='rb+' closefd=True>" mode='r+' encoding='utf-8'>> in_=<FDCapture 0 oldfd=3 _state='started' tmpfile=<_io.TextIOWrapper name='/dev/null' mode='r' encoding='utf-8'>> _state='suspended' _in_suspended=False> _capture_fixture=None>
          plugin_name: capturemanager
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
          plugin_name: session
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.cacheprovider.LFPlugin object at 0x7ff839798860>
          plugin_name: lfplugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.cacheprovider.NFPlugin object at 0x7ff839900f20>
          plugin_name: nfplugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <class '_pytest.legacypath.LegacyTmpdirPlugin'>
          plugin_name: legacypath-tmpdir
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.terminal.TerminalReporter object at 0x7ff8397ad010>
          plugin_name: terminalreporter
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.logging.LoggingPlugin object at 0x7ff83976e6c0>
          plugin_name: logging-plugin
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_plugin_registered [hook]
          plugin: <_pytest.fixtures.FixtureManager object at 0x7ff83976f920>
          plugin_name: funcmanage
          manager: <_pytest.config.PytestPluginManager object at 0x7ff839853e60>
      finish pytest_plugin_registered --> [] [hook]
      pytest_report_header [hook]
          config: <_pytest.config.Config object at 0x7ff839ea2b70>
          start_path: /app
          startdir: /app
      finish pytest_report_header --> [['rootdir: /app', 'configfile: pyproject.toml'], 'cachedir: .pytest_cache', ['using: pytest-8.4.0']] [hook]
    finish pytest_sessionstart --> [] [hook]
    pytest_collection [hook]
        session: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
    perform_collect <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0> ['tests/test_cli.py'] [collection]
        pytest_collectstart [hook]
            collector: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
        finish pytest_collectstart --> [] [hook]
        pytest_make_collect_report [hook]
            collector: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
        processing argument CollectionArgument(path=PosixPath('/app/tests/test_cli.py'), parts=[], module_name=None) [collection]
            pytest_collect_directory [hook]
                path: /app
                parent: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
            finish pytest_collect_directory --> <Dir app> [hook]
            pytest_collectstart [hook]
                collector: <Dir app>
            finish pytest_collectstart --> [] [hook]
            pytest_make_collect_report [hook]
                collector: <Dir app>
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/.git
                  path: /app/.git
              finish pytest_ignore_collect --> True [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/.gitignore
                  path: /app/.gitignore
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Dir app>
                  file_path: /app/.gitignore
                  path: /app/.gitignore
              finish pytest_collect_file --> [] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/.pytest_cache
                  path: /app/.pytest_cache
              finish pytest_ignore_collect --> True [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/LICENSE
                  path: /app/LICENSE
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Dir app>
                  file_path: /app/LICENSE
                  path: /app/LICENSE
              finish pytest_collect_file --> [] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/README.md
                  path: /app/README.md
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Dir app>
                  file_path: /app/README.md
                  path: /app/README.md
              finish pytest_collect_file --> [] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/pyproject.toml
                  path: /app/pyproject.toml
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Dir app>
                  file_path: /app/pyproject.toml
                  path: /app/pyproject.toml
              finish pytest_collect_file --> [] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/pytestdebug.log
                  path: /app/pytestdebug.log
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Dir app>
                  file_path: /app/pytestdebug.log
                  path: /app/pytestdebug.log
              finish pytest_collect_file --> [] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/src
                  path: /app/src
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_directory [hook]
                  path: /app/src
                  parent: <Dir app>
              finish pytest_collect_directory --> <Dir src> [hook]
              pytest_collect_directory [hook]
                  path: /app/tests
                  parent: <Dir app>
              finish pytest_collect_directory --> <Package tests> [hook]
            finish pytest_make_collect_report --> <CollectReport '.' lenresult=2 outcome='passed'> [hook]
            pytest_collectstart [hook]
                collector: <Package tests>
            finish pytest_collectstart --> [] [hook]
            pytest_make_collect_report [hook]
                collector: <Package tests>
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/tests/__init__.py
                  path: /app/tests/__init__.py
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Package tests>
                  file_path: /app/tests/__init__.py
                  path: /app/tests/__init__.py
              finish pytest_collect_file --> [] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/tests/__pycache__
                  path: /app/tests/__pycache__
              finish pytest_ignore_collect --> True [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/tests/fixture
                  path: /app/tests/fixture
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_directory [hook]
                  path: /app/tests/fixture
                  parent: <Package tests>
              finish pytest_collect_directory --> <Dir fixture> [hook]
              pytest_collect_file [hook]
                  parent: <Package tests>
                  file_path: /app/tests/test_cli.py
                  path: /app/tests/test_cli.py
                pytest_pycollect_makemodule [hook]
                    parent: <Package tests>
                    module_path: /app/tests/test_cli.py
                    path: /app/tests/test_cli.py
                finish pytest_pycollect_makemodule --> <Module test_cli.py> [hook]
              finish pytest_collect_file --> [<Module test_cli.py>] [hook]
              pytest_ignore_collect [hook]
                  config: <_pytest.config.Config object at 0x7ff839ea2b70>
                  collection_path: /app/tests/test_core.py
                  path: /app/tests/test_core.py
              finish pytest_ignore_collect --> None [hook]
              pytest_collect_file [hook]
                  parent: <Package tests>
                  file_path: /app/tests/test_core.py
                  path: /app/tests/test_core.py
                pytest_pycollect_makemodule [hook]
                    parent: <Package tests>
                    module_path: /app/tests/test_core.py
                    path: /app/tests/test_core.py
                finish pytest_pycollect_makemodule --> <Module test_core.py> [hook]
              finish pytest_collect_file --> [<Module test_core.py>] [hook]
            finish pytest_make_collect_report --> <CollectReport 'tests' lenresult=3 outcome='passed'> [hook]
        finish pytest_make_collect_report --> <CollectReport '' lenresult=1 outcome='passed'> [hook]
        pytest_collectreport [hook]
            report: <CollectReport '' lenresult=1 outcome='passed'>
        finish pytest_collectreport --> [] [hook]
    genitems <Module test_cli.py> [collection]
      pytest_collectstart [hook]
          collector: <Module test_cli.py>
      finish pytest_collectstart --> [] [hook]
      pytest_make_collect_report [hook]
          collector: <Module test_cli.py>
      early skip of rewriting module: tests [assertion]
      find_module called for: tests.test_cli [assertion]
      matched test file (was specified on cmdline): '/app/tests/test_cli.py' [assertion]
      _read_pyc(/app/tests/test_cli.py): out of date [assertion]
      rewriting PosixPath('/app/tests/test_cli.py') [assertion]
      early skip of rewriting module: unittest.mock [assertion]
      early skip of rewriting module: asyncio [assertion]
      early skip of rewriting module: asyncio.base_events [assertion]
      early skip of rewriting module: concurrent [assertion]
      early skip of rewriting module: concurrent.futures [assertion]
      early skip of rewriting module: concurrent.futures._base [assertion]
      early skip of rewriting module: ssl [assertion]
      early skip of rewriting module: _ssl [assertion]
      early skip of rewriting module: asyncio.constants [assertion]
      early skip of rewriting module: asyncio.coroutines [assertion]
      early skip of rewriting module: asyncio.events [assertion]
      early skip of rewriting module: contextvars [assertion]
      early skip of rewriting module: _contextvars [assertion]
      early skip of rewriting module: asyncio.format_helpers [assertion]
      early skip of rewriting module: _asyncio [assertion]
      early skip of rewriting module: asyncio.base_futures [assertion]
      early skip of rewriting module: asyncio.exceptions [assertion]
      early skip of rewriting module: asyncio.base_tasks [assertion]
      early skip of rewriting module: asyncio.futures [assertion]
      early skip of rewriting module: asyncio.protocols [assertion]
      early skip of rewriting module: asyncio.sslproto [assertion]
      early skip of rewriting module: asyncio.transports [assertion]
      early skip of rewriting module: asyncio.log [assertion]
      early skip of rewriting module: asyncio.staggered [assertion]
      early skip of rewriting module: asyncio.locks [assertion]
      early skip of rewriting module: asyncio.mixins [assertion]
      early skip of rewriting module: asyncio.tasks [assertion]
      early skip of rewriting module: asyncio.timeouts [assertion]
      early skip of rewriting module: asyncio.trsock [assertion]
      early skip of rewriting module: asyncio.runners [assertion]
      early skip of rewriting module: asyncio.queues [assertion]
      early skip of rewriting module: asyncio.streams [assertion]
      early skip of rewriting module: asyncio.subprocess [assertion]
      early skip of rewriting module: asyncio.taskgroups [assertion]
      early skip of rewriting module: asyncio.threads [assertion]
      early skip of rewriting module: asyncio.unix_events [assertion]
      early skip of rewriting module: asyncio.base_subprocess [assertion]
      early skip of rewriting module: asyncio.selector_events [assertion]
      early skip of rewriting module: pkgutil [assertion]
      early skip of rewriting module: pdf2mp3 [assertion]
      early skip of rewriting module: pdf2mp3 [assertion]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: @py_builtins
            obj: <module 'builtins' (built-in)>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: @pytest_ar
            obj: <module '_pytest.assertion.rewrite' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/_pytest/assertion/rewrite.py'>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: pytest
            obj: <module 'pytest' from '/home/jules/.local/share/pipx/venvs/pytest/lib/python3.12/site-packages/pytest/__init__.py'>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: Path
            obj: <class 'pathlib.Path'>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: subprocess
            obj: <module 'subprocess' from '/usr/lib/python3.12/subprocess.py'>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: mock
            obj: <module 'unittest.mock' from '/usr/lib/python3.12/unittest/mock.py'>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: sys
            obj: <module 'sys' (built-in)>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: cli
            obj: None
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: get_package_version
            obj: <function get_package_version at 0x7ff83977aa20>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: PKG_VERSION
            obj: 0.0.0
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: pytestmark
            obj: MarkDecorator(mark=Mark(name='skipif', args=(True,), kwargs={'reason': 'CLI module (or its dependencies like torch/TTS) not available for testing.'}))
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: mock_args
            obj: <pytest_fixture(<function mock_args at 0x7ff839828720>)>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: dummy_pdf
            obj: <pytest_fixture(<function dummy_pdf at 0x7ff8397e3ce0>)>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: mock_convert_pdf_to_mp3
            obj: <pytest_fixture(<function mock_convert_pdf_to_mp3 at 0x7ff839590040>)>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: run_cli_main_with_args
            obj: <function run_cli_main_with_args at 0x7ff839590220>
        finish pytest_pycollect_makeitem --> None [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_cli_invoked_no_args_shows_help
            obj: <function test_cli_invoked_no_args_shows_help at 0x7ff8395902c0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83a4a6ff0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_cli_invoked_no_args_shows_help>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_cli_version
            obj: <function test_cli_version at 0x7ff839590360>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976f6e0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_cli_version>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_cli_help
            obj: <function test_cli_help at 0x7ff839590400>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976f6e0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_cli_help>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_input_pdf_required
            obj: <function test_input_pdf_required at 0x7ff8395904a0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976f6e0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_input_pdf_required>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_output_mp3_optional_default
            obj: <function test_output_mp3_optional_default at 0x7ff839590540>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976ec30>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_output_mp3_optional_default>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_output_mp3_custom
            obj: <function test_output_mp3_custom at 0x7ff8395905e0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_output_mp3_custom>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_lang_option
            obj: <function test_lang_option at 0x7ff839590680>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_lang_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_voice_option
            obj: <function test_voice_option at 0x7ff839590720>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_voice_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_speed_option_valid
            obj: <function test_speed_option_valid at 0x7ff8395907c0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_speed_option_valid>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_speed_option_invalid_low
            obj: <function test_speed_option_invalid_low at 0x7ff839590860>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_speed_option_invalid_low>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_speed_option_invalid_high
            obj: <function test_speed_option_invalid_high at 0x7ff839590900>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_speed_option_invalid_high>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_split_pattern_option
            obj: <function test_split_pattern_option at 0x7ff8395909a0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_split_pattern_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_bitrate_option
            obj: <function test_bitrate_option at 0x7ff839590a40>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_bitrate_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_compression_option_valid
            obj: <function test_compression_option_valid at 0x7ff839590ae0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_compression_option_valid>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_compression_option_invalid_low
            obj: <function test_compression_option_invalid_low at 0x7ff839590b80>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_compression_option_invalid_low>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_compression_option_invalid_high
            obj: <function test_compression_option_invalid_high at 0x7ff839590c20>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_compression_option_invalid_high>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_device_option
            obj: <function test_device_option at 0x7ff839590cc0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_device_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_overwrite_option
            obj: <function test_overwrite_option at 0x7ff839590d60>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_overwrite_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_resume_option
            obj: <function test_resume_option at 0x7ff839590e00>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff83976fce0>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_resume_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_tmp_dir_option
            obj: <function test_tmp_dir_option at 0x7ff839590ea0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_tmp_dir_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_no_progress_option
            obj: <function test_no_progress_option at 0x7ff839590f40>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_no_progress_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_default_progress_option
            obj: <function test_default_progress_option at 0x7ff839590fe0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_default_progress_option>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_input_pdf_non_existent
            obj: <function test_input_pdf_non_existent at 0x7ff839591080>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_input_pdf_non_existent>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_core_convert_exception_handling
            obj: <function test_core_convert_exception_handling at 0x7ff839591120>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_core_convert_exception_handling>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_core_import_error_handling
            obj: <function test_core_import_error_handling at 0x7ff8395911c0>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_core_import_error_handling>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_all_defaults_passed_to_core
            obj: <function test_all_defaults_passed_to_core at 0x7ff839591260>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_all_defaults_passed_to_core>] [hook]
        pytest_pycollect_makeitem [hook]
            collector: <Module test_cli.py>
            name: test_bitrate_option_invalid_choice
            obj: <function test_bitrate_option_invalid_choice at 0x7ff839591300>
          pytest_generate_tests [hook]
              metafunc: <_pytest.python.Metafunc object at 0x7ff839563a10>
          finish pytest_generate_tests --> [] [hook]
        finish pytest_pycollect_makeitem --> [<Function test_bitrate_option_invalid_choice>] [hook]
      finish pytest_make_collect_report --> <CollectReport 'tests/test_cli.py' lenresult=27 outcome='passed'> [hook]
    genitems <Function test_cli_invoked_no_args_shows_help> [collection]
      pytest_itemcollected [hook]
          item: <Function test_cli_invoked_no_args_shows_help>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_cli_version> [collection]
      pytest_itemcollected [hook]
          item: <Function test_cli_version>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_cli_help> [collection]
      pytest_itemcollected [hook]
          item: <Function test_cli_help>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_input_pdf_required> [collection]
      pytest_itemcollected [hook]
          item: <Function test_input_pdf_required>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_output_mp3_optional_default> [collection]
      pytest_itemcollected [hook]
          item: <Function test_output_mp3_optional_default>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_output_mp3_custom> [collection]
      pytest_itemcollected [hook]
          item: <Function test_output_mp3_custom>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_lang_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_lang_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_voice_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_voice_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_speed_option_valid> [collection]
      pytest_itemcollected [hook]
          item: <Function test_speed_option_valid>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_speed_option_invalid_low> [collection]
      pytest_itemcollected [hook]
          item: <Function test_speed_option_invalid_low>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_speed_option_invalid_high> [collection]
      pytest_itemcollected [hook]
          item: <Function test_speed_option_invalid_high>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_split_pattern_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_split_pattern_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_bitrate_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_bitrate_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_compression_option_valid> [collection]
      pytest_itemcollected [hook]
          item: <Function test_compression_option_valid>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_compression_option_invalid_low> [collection]
      pytest_itemcollected [hook]
          item: <Function test_compression_option_invalid_low>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_compression_option_invalid_high> [collection]
      pytest_itemcollected [hook]
          item: <Function test_compression_option_invalid_high>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_device_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_device_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_overwrite_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_overwrite_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_resume_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_resume_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_tmp_dir_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_tmp_dir_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_no_progress_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_no_progress_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_default_progress_option> [collection]
      pytest_itemcollected [hook]
          item: <Function test_default_progress_option>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_input_pdf_non_existent> [collection]
      pytest_itemcollected [hook]
          item: <Function test_input_pdf_non_existent>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_core_convert_exception_handling> [collection]
      pytest_itemcollected [hook]
          item: <Function test_core_convert_exception_handling>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_core_import_error_handling> [collection]
      pytest_itemcollected [hook]
          item: <Function test_core_import_error_handling>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_all_defaults_passed_to_core> [collection]
      pytest_itemcollected [hook]
          item: <Function test_all_defaults_passed_to_core>
      finish pytest_itemcollected --> [] [hook]
    genitems <Function test_bitrate_option_invalid_choice> [collection]
      pytest_itemcollected [hook]
          item: <Function test_bitrate_option_invalid_choice>
      finish pytest_itemcollected --> [] [hook]
      pytest_collectreport [hook]
          report: <CollectReport 'tests/test_cli.py' lenresult=27 outcome='passed'>
      finish pytest_collectreport --> [] [hook]
      pytest_collection_modifyitems [hook]
          session: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
          config: <_pytest.config.Config object at 0x7ff839ea2b70>
          items: [<Function test_cli_invoked_no_args_shows_help>, <Function test_cli_version>, <Function test_cli_help>, <Function test_input_pdf_required>, <Function test_output_mp3_optional_default>, <Function test_output_mp3_custom>, <Function test_lang_option>, <Function test_voice_option>, <Function test_speed_option_valid>, <Function test_speed_option_invalid_low>, <Function test_speed_option_invalid_high>, <Function test_split_pattern_option>, <Function test_bitrate_option>, <Function test_compression_option_valid>, <Function test_compression_option_invalid_low>, <Function test_compression_option_invalid_high>, <Function test_device_option>, <Function test_overwrite_option>, <Function test_resume_option>, <Function test_tmp_dir_option>, <Function test_no_progress_option>, <Function test_default_progress_option>, <Function test_input_pdf_non_existent>, <Function test_core_convert_exception_handling>, <Function test_core_import_error_handling>, <Function test_all_defaults_passed_to_core>, <Function test_bitrate_option_invalid_choice>]
      finish pytest_collection_modifyitems --> [] [hook]
      pytest_collection_finish [hook]
          session: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=0>
        pytest_report_collectionfinish [hook]
            config: <_pytest.config.Config object at 0x7ff839ea2b70>
            items: [<Function test_cli_invoked_no_args_shows_help>, <Function test_cli_version>, <Function test_cli_help>, <Function test_input_pdf_required>, <Function test_output_mp3_optional_default>, <Function test_output_mp3_custom>, <Function test_lang_option>, <Function test_voice_option>, <Function test_speed_option_valid>, <Function test_speed_option_invalid_low>, <Function test_speed_option_invalid_high>, <Function test_split_pattern_option>, <Function test_bitrate_option>, <Function test_compression_option_valid>, <Function test_compression_option_invalid_low>, <Function test_compression_option_invalid_high>, <Function test_device_option>, <Function test_overwrite_option>, <Function test_resume_option>, <Function test_tmp_dir_option>, <Function test_no_progress_option>, <Function test_default_progress_option>, <Function test_input_pdf_non_existent>, <Function test_core_convert_exception_handling>, <Function test_core_import_error_handling>, <Function test_all_defaults_passed_to_core>, <Function test_bitrate_option_invalid_choice>]
            start_path: /app
            startdir: /app
        finish pytest_report_collectionfinish --> [] [hook]
      finish pytest_collection_finish --> [] [hook]
    finish pytest_collection --> None [hook]
    pytest_runtestloop [hook]
        session: <Session  exitstatus=<ExitCode.OK: 0> testsfailed=0 testscollected=27>
      pytest_runtest_protocol [hook]
          item: <Function test_cli_invoked_no_args_shows_help>
          nextitem: <Function test_cli_version>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_cli_invoked_no_args_shows_help
            location: ('tests/test_cli.py', 116, 'test_cli_invoked_no_args_shows_help')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_cli_invoked_no_args_shows_help>
        pytest_runtest_makereport [hook]
            item: <Function test_cli_invoked_no_args_shows_help>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_cli_invoked_no_args_shows_help' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_cli_invoked_no_args_shows_help' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_cli_invoked_no_args_shows_help' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_cli_invoked_no_args_shows_help>
            nextitem: <Function test_cli_version>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_cli_invoked_no_args_shows_help>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_cli_invoked_no_args_shows_help' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_cli_invoked_no_args_shows_help' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_cli_invoked_no_args_shows_help' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_cli_invoked_no_args_shows_help
            location: ('tests/test_cli.py', 116, 'test_cli_invoked_no_args_shows_help')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_cli_version>
          nextitem: <Function test_cli_help>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_cli_version
            location: ('tests/test_cli.py', 125, 'test_cli_version')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_cli_version>
        pytest_runtest_makereport [hook]
            item: <Function test_cli_version>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_cli_version' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_cli_version' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_cli_version' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_cli_version>
            nextitem: <Function test_cli_help>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_cli_version>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_cli_version' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_cli_version' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_cli_version' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_cli_version
            location: ('tests/test_cli.py', 125, 'test_cli_version')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_cli_help>
          nextitem: <Function test_input_pdf_required>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_cli_help
            location: ('tests/test_cli.py', 132, 'test_cli_help')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_cli_help>
        pytest_runtest_makereport [hook]
            item: <Function test_cli_help>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_cli_help' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_cli_help' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_cli_help' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_cli_help>
            nextitem: <Function test_input_pdf_required>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_cli_help>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_cli_help' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_cli_help' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_cli_help' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_cli_help
            location: ('tests/test_cli.py', 132, 'test_cli_help')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_input_pdf_required>
          nextitem: <Function test_output_mp3_optional_default>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_input_pdf_required
            location: ('tests/test_cli.py', 140, 'test_input_pdf_required')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_input_pdf_required>
        pytest_runtest_makereport [hook]
            item: <Function test_input_pdf_required>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_input_pdf_required' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_input_pdf_required' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_input_pdf_required' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_input_pdf_required>
            nextitem: <Function test_output_mp3_optional_default>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_input_pdf_required>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_input_pdf_required' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_input_pdf_required' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_input_pdf_required' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_input_pdf_required
            location: ('tests/test_cli.py', 140, 'test_input_pdf_required')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_output_mp3_optional_default>
          nextitem: <Function test_output_mp3_custom>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_output_mp3_optional_default
            location: ('tests/test_cli.py', 148, 'test_output_mp3_optional_default')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_output_mp3_optional_default>
        pytest_runtest_makereport [hook]
            item: <Function test_output_mp3_optional_default>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_output_mp3_optional_default' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_output_mp3_optional_default' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_output_mp3_optional_default' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_output_mp3_optional_default>
            nextitem: <Function test_output_mp3_custom>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_output_mp3_optional_default>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_output_mp3_optional_default' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_output_mp3_optional_default' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_output_mp3_optional_default' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_output_mp3_optional_default
            location: ('tests/test_cli.py', 148, 'test_output_mp3_optional_default')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_output_mp3_custom>
          nextitem: <Function test_lang_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_output_mp3_custom
            location: ('tests/test_cli.py', 157, 'test_output_mp3_custom')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_output_mp3_custom>
        pytest_runtest_makereport [hook]
            item: <Function test_output_mp3_custom>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_output_mp3_custom' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_output_mp3_custom' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_output_mp3_custom' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_output_mp3_custom>
            nextitem: <Function test_lang_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_output_mp3_custom>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_output_mp3_custom' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_output_mp3_custom' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_output_mp3_custom' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_output_mp3_custom
            location: ('tests/test_cli.py', 157, 'test_output_mp3_custom')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_lang_option>
          nextitem: <Function test_voice_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_lang_option
            location: ('tests/test_cli.py', 167, 'test_lang_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_lang_option>
        pytest_runtest_makereport [hook]
            item: <Function test_lang_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_lang_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_lang_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_lang_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_lang_option>
            nextitem: <Function test_voice_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_lang_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_lang_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_lang_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_lang_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_lang_option
            location: ('tests/test_cli.py', 167, 'test_lang_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_voice_option>
          nextitem: <Function test_speed_option_valid>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_voice_option
            location: ('tests/test_cli.py', 173, 'test_voice_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_voice_option>
        pytest_runtest_makereport [hook]
            item: <Function test_voice_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_voice_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_voice_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_voice_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_voice_option>
            nextitem: <Function test_speed_option_valid>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_voice_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_voice_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_voice_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_voice_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_voice_option
            location: ('tests/test_cli.py', 173, 'test_voice_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_speed_option_valid>
          nextitem: <Function test_speed_option_invalid_low>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_speed_option_valid
            location: ('tests/test_cli.py', 179, 'test_speed_option_valid')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_speed_option_valid>
        pytest_runtest_makereport [hook]
            item: <Function test_speed_option_valid>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_speed_option_valid' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_speed_option_valid' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_speed_option_valid' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_speed_option_valid>
            nextitem: <Function test_speed_option_invalid_low>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_speed_option_valid>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_speed_option_valid' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_speed_option_valid' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_speed_option_valid' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_speed_option_valid
            location: ('tests/test_cli.py', 179, 'test_speed_option_valid')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_speed_option_invalid_low>
          nextitem: <Function test_speed_option_invalid_high>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_speed_option_invalid_low
            location: ('tests/test_cli.py', 185, 'test_speed_option_invalid_low')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_speed_option_invalid_low>
        pytest_runtest_makereport [hook]
            item: <Function test_speed_option_invalid_low>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_speed_option_invalid_low' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_low' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_low' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_speed_option_invalid_low>
            nextitem: <Function test_speed_option_invalid_high>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_speed_option_invalid_low>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_speed_option_invalid_low' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_low' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_low' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_speed_option_invalid_low
            location: ('tests/test_cli.py', 185, 'test_speed_option_invalid_low')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_speed_option_invalid_high>
          nextitem: <Function test_split_pattern_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_speed_option_invalid_high
            location: ('tests/test_cli.py', 191, 'test_speed_option_invalid_high')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_speed_option_invalid_high>
        pytest_runtest_makereport [hook]
            item: <Function test_speed_option_invalid_high>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_speed_option_invalid_high' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_high' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_high' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_speed_option_invalid_high>
            nextitem: <Function test_split_pattern_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_speed_option_invalid_high>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_speed_option_invalid_high' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_high' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_speed_option_invalid_high' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_speed_option_invalid_high
            location: ('tests/test_cli.py', 191, 'test_speed_option_invalid_high')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_split_pattern_option>
          nextitem: <Function test_bitrate_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_split_pattern_option
            location: ('tests/test_cli.py', 197, 'test_split_pattern_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_split_pattern_option>
        pytest_runtest_makereport [hook]
            item: <Function test_split_pattern_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_split_pattern_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_split_pattern_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_split_pattern_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_split_pattern_option>
            nextitem: <Function test_bitrate_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_split_pattern_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_split_pattern_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_split_pattern_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_split_pattern_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_split_pattern_option
            location: ('tests/test_cli.py', 197, 'test_split_pattern_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_bitrate_option>
          nextitem: <Function test_compression_option_valid>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_bitrate_option
            location: ('tests/test_cli.py', 204, 'test_bitrate_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_bitrate_option>
        pytest_runtest_makereport [hook]
            item: <Function test_bitrate_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_bitrate_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_bitrate_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_bitrate_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_bitrate_option>
            nextitem: <Function test_compression_option_valid>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_bitrate_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_bitrate_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_bitrate_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_bitrate_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_bitrate_option
            location: ('tests/test_cli.py', 204, 'test_bitrate_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_compression_option_valid>
          nextitem: <Function test_compression_option_invalid_low>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_compression_option_valid
            location: ('tests/test_cli.py', 210, 'test_compression_option_valid')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_compression_option_valid>
        pytest_runtest_makereport [hook]
            item: <Function test_compression_option_valid>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_compression_option_valid' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_compression_option_valid' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_compression_option_valid' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_compression_option_valid>
            nextitem: <Function test_compression_option_invalid_low>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_compression_option_valid>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_compression_option_valid' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_compression_option_valid' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_compression_option_valid' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_compression_option_valid
            location: ('tests/test_cli.py', 210, 'test_compression_option_valid')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_compression_option_invalid_low>
          nextitem: <Function test_compression_option_invalid_high>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_compression_option_invalid_low
            location: ('tests/test_cli.py', 216, 'test_compression_option_invalid_low')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_compression_option_invalid_low>
        pytest_runtest_makereport [hook]
            item: <Function test_compression_option_invalid_low>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_compression_option_invalid_low' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_low' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_low' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_compression_option_invalid_low>
            nextitem: <Function test_compression_option_invalid_high>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_compression_option_invalid_low>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_compression_option_invalid_low' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_low' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_low' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_compression_option_invalid_low
            location: ('tests/test_cli.py', 216, 'test_compression_option_invalid_low')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_compression_option_invalid_high>
          nextitem: <Function test_device_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_compression_option_invalid_high
            location: ('tests/test_cli.py', 222, 'test_compression_option_invalid_high')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_compression_option_invalid_high>
        pytest_runtest_makereport [hook]
            item: <Function test_compression_option_invalid_high>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_compression_option_invalid_high' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_high' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_high' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_compression_option_invalid_high>
            nextitem: <Function test_device_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_compression_option_invalid_high>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_compression_option_invalid_high' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_high' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_compression_option_invalid_high' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_compression_option_invalid_high
            location: ('tests/test_cli.py', 222, 'test_compression_option_invalid_high')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_device_option>
          nextitem: <Function test_overwrite_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_device_option
            location: ('tests/test_cli.py', 229, 'test_device_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_device_option>
        pytest_runtest_makereport [hook]
            item: <Function test_device_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_device_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_device_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_device_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_device_option>
            nextitem: <Function test_overwrite_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_device_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_device_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_device_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_device_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_device_option
            location: ('tests/test_cli.py', 229, 'test_device_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_overwrite_option>
          nextitem: <Function test_resume_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_overwrite_option
            location: ('tests/test_cli.py', 235, 'test_overwrite_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_overwrite_option>
        pytest_runtest_makereport [hook]
            item: <Function test_overwrite_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_overwrite_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_overwrite_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_overwrite_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_overwrite_option>
            nextitem: <Function test_resume_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_overwrite_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_overwrite_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_overwrite_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_overwrite_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_overwrite_option
            location: ('tests/test_cli.py', 235, 'test_overwrite_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_resume_option>
          nextitem: <Function test_tmp_dir_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_resume_option
            location: ('tests/test_cli.py', 241, 'test_resume_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_resume_option>
        pytest_runtest_makereport [hook]
            item: <Function test_resume_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_resume_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_resume_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_resume_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_resume_option>
            nextitem: <Function test_tmp_dir_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_resume_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_resume_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_resume_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_resume_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_resume_option
            location: ('tests/test_cli.py', 241, 'test_resume_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_tmp_dir_option>
          nextitem: <Function test_no_progress_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_tmp_dir_option
            location: ('tests/test_cli.py', 247, 'test_tmp_dir_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_tmp_dir_option>
        pytest_runtest_makereport [hook]
            item: <Function test_tmp_dir_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_tmp_dir_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_tmp_dir_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_tmp_dir_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_tmp_dir_option>
            nextitem: <Function test_no_progress_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_tmp_dir_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_tmp_dir_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_tmp_dir_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_tmp_dir_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_tmp_dir_option
            location: ('tests/test_cli.py', 247, 'test_tmp_dir_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_no_progress_option>
          nextitem: <Function test_default_progress_option>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_no_progress_option
            location: ('tests/test_cli.py', 254, 'test_no_progress_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_no_progress_option>
        pytest_runtest_makereport [hook]
            item: <Function test_no_progress_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_no_progress_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_no_progress_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_no_progress_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_no_progress_option>
            nextitem: <Function test_default_progress_option>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_no_progress_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_no_progress_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_no_progress_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_no_progress_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_no_progress_option
            location: ('tests/test_cli.py', 254, 'test_no_progress_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_default_progress_option>
          nextitem: <Function test_input_pdf_non_existent>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_default_progress_option
            location: ('tests/test_cli.py', 260, 'test_default_progress_option')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_default_progress_option>
        pytest_runtest_makereport [hook]
            item: <Function test_default_progress_option>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_default_progress_option' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_default_progress_option' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_default_progress_option' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_default_progress_option>
            nextitem: <Function test_input_pdf_non_existent>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_default_progress_option>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_default_progress_option' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_default_progress_option' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_default_progress_option' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_default_progress_option
            location: ('tests/test_cli.py', 260, 'test_default_progress_option')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_input_pdf_non_existent>
          nextitem: <Function test_core_convert_exception_handling>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_input_pdf_non_existent
            location: ('tests/test_cli.py', 268, 'test_input_pdf_non_existent')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_input_pdf_non_existent>
        pytest_runtest_makereport [hook]
            item: <Function test_input_pdf_non_existent>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_input_pdf_non_existent' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_input_pdf_non_existent' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_input_pdf_non_existent' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_input_pdf_non_existent>
            nextitem: <Function test_core_convert_exception_handling>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_input_pdf_non_existent>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_input_pdf_non_existent' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_input_pdf_non_existent' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_input_pdf_non_existent' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_input_pdf_non_existent
            location: ('tests/test_cli.py', 268, 'test_input_pdf_non_existent')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_core_convert_exception_handling>
          nextitem: <Function test_core_import_error_handling>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_core_convert_exception_handling
            location: ('tests/test_cli.py', 276, 'test_core_convert_exception_handling')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_core_convert_exception_handling>
        pytest_runtest_makereport [hook]
            item: <Function test_core_convert_exception_handling>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_core_convert_exception_handling' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_core_convert_exception_handling' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_core_convert_exception_handling' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_core_convert_exception_handling>
            nextitem: <Function test_core_import_error_handling>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_core_convert_exception_handling>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_core_convert_exception_handling' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_core_convert_exception_handling' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_core_convert_exception_handling' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_core_convert_exception_handling
            location: ('tests/test_cli.py', 276, 'test_core_convert_exception_handling')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_core_import_error_handling>
          nextitem: <Function test_all_defaults_passed_to_core>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_core_import_error_handling
            location: ('tests/test_cli.py', 294, 'test_core_import_error_handling')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_core_import_error_handling>
        pytest_runtest_makereport [hook]
            item: <Function test_core_import_error_handling>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_core_import_error_handling' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_core_import_error_handling' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_core_import_error_handling' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_core_import_error_handling>
            nextitem: <Function test_all_defaults_passed_to_core>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_core_import_error_handling>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_core_import_error_handling' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_core_import_error_handling' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_core_import_error_handling' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_core_import_error_handling
            location: ('tests/test_cli.py', 294, 'test_core_import_error_handling')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_all_defaults_passed_to_core>
          nextitem: <Function test_bitrate_option_invalid_choice>
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_all_defaults_passed_to_core
            location: ('tests/test_cli.py', 339, 'test_all_defaults_passed_to_core')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_all_defaults_passed_to_core>
        pytest_runtest_makereport [hook]
            item: <Function test_all_defaults_passed_to_core>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_all_defaults_passed_to_core' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_all_defaults_passed_to_core' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_all_defaults_passed_to_core' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_all_defaults_passed_to_core>
            nextitem: <Function test_bitrate_option_invalid_choice>
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_all_defaults_passed_to_core>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_all_defaults_passed_to_core' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_all_defaults_passed_to_core' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_all_defaults_passed_to_core' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_all_defaults_passed_to_core
            location: ('tests/test_cli.py', 339, 'test_all_defaults_passed_to_core')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
      pytest_runtest_protocol [hook]
          item: <Function test_bitrate_option_invalid_choice>
          nextitem: None
        pytest_runtest_logstart [hook]
            nodeid: tests/test_cli.py::test_bitrate_option_invalid_choice
            location: ('tests/test_cli.py', 389, 'test_bitrate_option_invalid_choice')
        finish pytest_runtest_logstart --> [] [hook]
        pytest_runtest_setup [hook]
            item: <Function test_bitrate_option_invalid_choice>
        pytest_runtest_makereport [hook]
            item: <Function test_bitrate_option_invalid_choice>
            call: <CallInfo when='setup' excinfo=<ExceptionInfo CLI module (or its dependencies like torch/TTS) not available for testing. tblen=15>>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_bitrate_option_invalid_choice' when='setup' outcome='skipped'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_bitrate_option_invalid_choice' when='setup' outcome='skipped'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_bitrate_option_invalid_choice' when='setup' outcome='skipped'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('skipped', 's', 'SKIPPED') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_teardown [hook]
            item: <Function test_bitrate_option_invalid_choice>
            nextitem: None
        finish pytest_runtest_teardown --> None [hook]
        pytest_runtest_makereport [hook]
            item: <Function test_bitrate_option_invalid_choice>
            call: <CallInfo when='teardown' result: None>
        finish pytest_runtest_makereport --> <TestReport 'tests/test_cli.py::test_bitrate_option_invalid_choice' when='teardown' outcome='passed'> [hook]
        pytest_runtest_logreport [hook]
            report: <TestReport 'tests/test_cli.py::test_bitrate_option_invalid_choice' when='teardown' outcome='passed'>
          pytest_report_teststatus [hook]
              report: <TestReport 'tests/test_cli.py::test_bitrate_option_invalid_choice' when='teardown' outcome='passed'>
              config: <_pytest.config.Config object at 0x7ff839ea2b70>
          finish pytest_report_teststatus --> ('', '', '') [hook]
        finish pytest_runtest_logreport --> [] [hook]
        pytest_runtest_logfinish [hook]
            nodeid: tests/test_cli.py::test_bitrate_option_invalid_choice
            location: ('tests/test_cli.py', 389, 'test_bitrate_option_invalid_choice')
        finish pytest_runtest_logfinish --> [] [hook]
      finish pytest_runtest_protocol --> True [hook]
    finish pytest_runtestloop --> True [hook]
    pytest_sessionfinish [hook]
        session: <Session  exitstatus=0 testsfailed=0 testscollected=27>
        exitstatus: 0
      pytest_terminal_summary [hook]
          terminalreporter: <_pytest.terminal.TerminalReporter object at 0x7ff8397ad010>
          exitstatus: 0
          config: <_pytest.config.Config object at 0x7ff839ea2b70>
      finish pytest_terminal_summary --> [] [hook]
    finish pytest_sessionfinish --> [] [hook]
    pytest_unconfigure [hook]
        config: <_pytest.config.Config object at 0x7ff839ea2b70>
    finish pytest_unconfigure --> [] [hook]
